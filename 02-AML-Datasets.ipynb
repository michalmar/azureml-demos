{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with AML Datasets & Data in general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check core SDK version number\n",
    "import azureml.core\n",
    "import mlflow\n",
    "import os\n",
    "\n",
    "from azureml.core import (Datastore, Dataset, Environment, Experiment, ScriptRunConfig,\n",
    "                          Workspace)\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "\n",
    "print(\"[INFO] SDK version:\", azureml.core.VERSION)\n",
    "\n",
    "## due to diferent tenant -> typically customer tenant\n",
    "# interactive_auth = InteractiveLoginAuthentication(tenant_id=\"72f988bf-86f1-41af-91ab-2d7cd011db47\")\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(\"[SUCCESS] LOGGED IN: \",ws.name, ws.resource_group, ws.location, ws.subscription_id, sep=' @ ')\n",
    "\n",
    "## set mlflow backend to AML\n",
    "mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\n",
    "\n",
    "print(\"[INFO] MLFlow wired to AML:\", \"experiments.azureml.net\" in mlflow.get_tracking_uri())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml_compute = \"aml-cluster\"\n",
    "aml_ds = \"aml_data\"# \"mmaadlsgen2_test\"\n",
    "# aml_dset = 'noa_weather'\n",
    "# aml_dset = \"oj_sample_data\"\n",
    "aml_dset = \"diabetes_multiple\"\n",
    "aml_experiment = \"mlflow-azureml\"\n",
    "loc_data = \"data/demo_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf $loc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## List all datastores registered in the current workspace\n",
    "datastores = ws.datastores\n",
    "for name, datastore in datastores.items():\n",
    "    print(f\"{name} ({datastore.datastore_type})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set the datastore\n",
    "ds = ws.datastores[aml_ds]\n",
    "print(f\"[INFO] Datastore: {ds.name}, type: {ds.datastore_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Dataset\n",
    "\n",
    "```python\n",
    "from_files(path, validate=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a FileDataset pointing to files in 'diabetes' folder and its subfolders recursively\n",
    "\n",
    "# datastore_paths = [(ds, 'diabetes')]\n",
    "# datastore_paths = [(ds, 'diabetes/diabetes0.csv'),(ds, 'diabetes/diabetes1.csv'),(ds, 'diabetes/diabetes2.csv')]\n",
    "datastore_paths = [(ds, 'diabetes/diabetes*.csv')]\n",
    "# datastore_paths = [(ds, 'ojs/Store140*.csv')]\n",
    "\n",
    "fds = Dataset.File.from_files(path=datastore_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## show files matching criteria into paths\n",
    "fds.to_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## download just a sample of the data\n",
    "fds.take(3).download(target_path=os.path.join(\"./\",loc_data), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check donwloaded files\n",
    "tmppath = os.path.join(\"./\",loc_data)\n",
    "onlyfiles = [f for f in os.listdir(tmppath) if os.path.isfile(os.path.join(tmppath, f))]\n",
    "print(onlyfiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabular Dataset\n",
    "\n",
    "```python\n",
    "from_delimited_files(path, separator=',', header=<PromoteHeadersBehavior.ALL_FILES_HAVE_SAME_HEADERS: 3>, encoding=<FileEncoding.UTF8: 0>, quoting=False, infer_column_types=True, skip_rows=0, skip_mode=<SkipLinesBehavior.NO_ROWS: 0>, comment=None, include_path=False, archive_options=None, partition_format=None)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a FileDataset pointing to files in 'weather' folder and its subfolders recursively\n",
    "\n",
    "# datastore_paths = [(ds, 'diabetes')]\n",
    "# datastore_paths = [(ds, 'diabetes/diabetes0.csv'),(ds, 'diabetes/diabetes1.csv'),(ds, 'diabetes/diabetes2.csv')]\n",
    "datastore_paths = [(ds, 'diabetes/diabetes*.csv')]\n",
    "# datastore_paths = [(ds, 'ojs/Store140*.csv')]\n",
    "\n",
    "tds = Dataset.Tabular.from_delimited_files(path=datastore_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = tds.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## register Dataset into Workspace for reusability\n",
    "\n",
    "wtds = tds.register(workspace=ws, name=aml_dset, description='Sample: Diabetes data from Azure Open Datasets',create_new_version=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wtds_profile = wtds.get_profile(ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get data from existing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtds = Dataset.get_by_name(ws, name=aml_dset)\n",
    "wtds.to_pandas_dataframe().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(aml_experiment)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
